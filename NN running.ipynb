{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "# df = df.reindex(np.random.permutation(df.index)) # shuffling the data\n",
    "df.describe()\n",
    "# df = df.sample(5000)\n",
    "features = df.columns[df.dtypes == np.float64]\n",
    "target = ' shares'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = preprocessing.MinMaxScaler().fit_transform(df[features])\n",
    "Y = np.log(df[target])\n",
    "\n",
    "N = X.shape[0]\n",
    "\n",
    "split = np.round(np.array([0.7, 0.85]) * N).astype(np.int)\n",
    "X_t, X_cv, X_test = np.array_split(X, split)\n",
    "Y_t, Y_cv, Y_test = np.array_split(Y.reshape(-1, 1), split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 5 3 7 9]\n",
      " [4 6 4 1 4]\n",
      " [8 1 6 5 9]\n",
      " [4 6 9 2 5]\n",
      " [8 5 3 3 2]\n",
      " [9 2 1 3 7]\n",
      " [8 4 4 3 4]\n",
      " [8 5 8 1 1]\n",
      " [5 1 2 6 9]\n",
      " [6 3 8 1 5]\n",
      " [0 6 8 4 0]\n",
      " [6 5 9 7 5]] [[49 88]\n",
      " [59 59]\n",
      " [50 65]\n",
      " [47 29]\n",
      " [78 29]\n",
      " [71 39]\n",
      " [12 50]\n",
      " [90 59]\n",
      " [55 88]\n",
      " [30 64]\n",
      " [76 52]\n",
      " [32 89]]\n",
      "[[9 2 1 3 7]] [[71 39]]\n",
      "[[4 6 9 2 5]] [[47 29]]\n",
      "[[4 6 4 1 4]] [[59 59]]\n",
      "[[0 6 8 4 0]] [[76 52]]\n",
      "[[6 3 8 1 5]] [[30 64]]\n",
      "[[8 1 6 5 9]] [[50 65]]\n",
      "[[8 5 3 3 2]] [[78 29]]\n",
      "[[8 4 4 3 4]] [[12 50]]\n",
      "[[8 5 3 7 9]] [[49 88]]\n",
      "[[6 5 9 7 5]] [[32 89]]\n",
      "[[8 5 8 1 1]] [[90 59]]\n",
      "[[5 1 2 6 9]] [[55 88]]\n",
      "\n",
      "[[0 6 8 4 0]\n",
      " [8 5 3 7 9]\n",
      " [8 1 6 5 9]\n",
      " [6 3 8 1 5]\n",
      " [8 4 4 3 4]] [[76 52]\n",
      " [49 88]\n",
      " [50 65]\n",
      " [30 64]\n",
      " [12 50]]\n",
      "[[8 5 3 3 2]\n",
      " [4 6 4 1 4]\n",
      " [6 5 9 7 5]\n",
      " [8 5 8 1 1]\n",
      " [4 6 9 2 5]] [[78 29]\n",
      " [59 59]\n",
      " [32 89]\n",
      " [90 59]\n",
      " [47 29]]\n",
      "[[5 1 2 6 9]\n",
      " [9 2 1 3 7]] [[55 88]\n",
      " [71 39]]\n"
     ]
    }
   ],
   "source": [
    "class BatchGenerator():\n",
    "    def __init__(self, X, Y):\n",
    "        self.N, self.n = X.shape\n",
    "        self.data = np.hstack([X, Y])\n",
    "    def gen(self, batchSize):\n",
    "        np.random.shuffle(self.data)\n",
    "        for i in range(0, self.N, batchSize):\n",
    "            yield \\\n",
    "                self.data[i:i+batchSize, :self.n], \\\n",
    "                self.data[i:i+batchSize, self.n:]\n",
    "\n",
    "XX = np.random.randint(0, 10, (12, 5))\n",
    "YY = np.random.randint(10, 100, (12, 2))\n",
    "\n",
    "print (XX, YY)\n",
    "\n",
    "G = BatchGenerator(XX, YY)\n",
    "\n",
    "for x, y in G.gen(1):\n",
    "    print(x, y)\n",
    "print()\n",
    "for x, y in G.gen(5):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] train:    4.8347941635, test:    4.7975316297\n",
      "[ 10] train:    3.1955308163, test:    3.1674724524\n",
      "[ 20] train:    2.1438993485, test:    2.1074122587\n",
      "[ 30] train:    1.6378769157, test:    1.6154305317\n",
      "[ 40] train:    0.9004661545, test:    0.8458583064\n",
      "[ 50] train:    0.8826373441, test:    0.8441244284\n",
      "[ 60] train:    0.9047360106, test:    0.8946935848\n",
      "[ 70] train:    0.8785453225, test:    0.8543541671\n",
      "[ 80] train:    0.8836921428, test:    0.8405537642\n",
      "[ 90] train:    0.8746578365, test:    0.8479274896\n",
      "[100] train:    0.8903216799, test:    0.8425722026\n",
      "[110] train:    0.8793159378, test:    0.8743849364\n",
      "[120] train:    0.8712526185, test:    0.8613106516\n",
      "[130] train:    0.8852426283, test:    0.8404895872\n",
      "[140] train:    0.9109614989, test:    0.9336020178\n",
      "[150] train:    0.8721469961, test:    0.8725087259\n",
      "[160] train:    0.8602028414, test:    0.8446167274\n",
      "[170] train:    0.8606152688, test:    0.8414722357\n",
      "[180] train:    0.8635704971, test:    0.8676987593\n",
      "[190] train:    0.8574290351, test:    0.8645749302\n",
      "[200] train:    0.8537711453, test:    0.8422061784\n",
      "[210] train:    0.8719582480, test:    0.8979016572\n",
      "[220] train:    0.8505699253, test:    0.8565979216\n",
      "[230] train:    0.8474964044, test:    0.8553906758\n",
      "[240] train:    0.8965649870, test:    0.8649831368\n",
      "[250] train:    0.8630258864, test:    0.8450568992\n",
      "[260] train:    0.8450756609, test:    0.8444996788\n",
      "[270] train:    0.8423162924, test:    0.8464071678\n",
      "[280] train:    0.8405669891, test:    0.8673583198\n",
      "[290] train:    0.8461626668, test:    0.8813264205\n",
      "[300] train:    0.8440199173, test:    0.8840727799\n",
      "[310] train:    0.8428086222, test:    0.8474679905\n",
      "[320] train:    0.8350659756, test:    0.8543063414\n",
      "[330] train:    0.8371552840, test:    0.8926669688\n",
      "[340] train:    0.8287744674, test:    0.8608142245\n",
      "[350] train:    0.8249111431, test:    0.8786624146\n",
      "[360] train:    0.8269718707, test:    0.8654210425\n",
      "[370] train:    0.8185183569, test:    0.8811748134\n",
      "[380] train:    0.8353277104, test:    0.8635620075\n",
      "[390] train:    0.8272534589, test:    0.8892653276\n",
      "[400] train:    0.8189431887, test:    0.8655043067\n",
      "[410] train:    0.8086509500, test:    0.8829213641\n",
      "[420] train:    0.8197363874, test:    0.9257038583\n",
      "[430] train:    0.8263065237, test:    0.9482509876\n",
      "[440] train:    0.8033200840, test:    0.8842594813\n",
      "[450] train:    0.8535381812, test:    0.9769845890\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-aef9bfab2ebc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoh\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             training_cost = sess.run(cost, feed_dict={\n",
      "\u001b[1;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    642\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m--> 628\u001b[1;33m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 59], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal(shape=[59,100], stddev=59**-0.5), name=\"weights\")\n",
    "b_1 = tf.Variable(tf.random_normal(shape=[1 ,100]), name=\"bias\")\n",
    "a_1 = tf.nn.tanh(tf.matmul(x, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal(shape=[100,50], stddev=0.1), name=\"weights\")\n",
    "b_2 = tf.Variable(tf.random_normal(shape=[1,50]), name=\"bias\")\n",
    "a_2 = tf.nn.relu6(tf.matmul(a_1, W_2) + b_2)\n",
    "\n",
    "W_3 = tf.Variable(tf.random_normal(shape=[50,30], stddev=0.1), name=\"weights\")\n",
    "b_3 = tf.Variable(tf.random_normal(shape=[1,1]), name=\"bias\")\n",
    "a_3 = tf.nn.relu(tf.matmul(a_2, W_3) + b_3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - a_3))\n",
    "train_step = tf.train.MomentumOptimizer(1e-1, 0.0).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    T = BatchGenerator(X_t, Y_t)\n",
    "    \n",
    "    for epoh in range(1000):\n",
    "        for xs, ys in T.gen(128):\n",
    "            sess.run(train_step, feed_dict={x: xs, y: ys})\n",
    "        if epoh % 10 == 0:\n",
    "            training_cost = sess.run(cost, feed_dict={\n",
    "                    x:X_t,\n",
    "                    y:Y_t\n",
    "                })\n",
    "            test_cost = sess.run(cost, feed_dict={\n",
    "                        x: X_cv,\n",
    "                        y: Y_cv\n",
    "                    })\n",
    "            print (\"[%3d] train: %15.10f, test: %15.10f\" % \\\n",
    "                   (epoh, training_cost**0.5, test_cost**0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
